{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Segmentation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utilities.sql import SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "sql = SQL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean-21st-century-data.csv\")\n",
    "df[\"Customer Invoice Date\"] = pd.to_datetime(df[\"Customer Invoice Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT m.name AS make, mm.model AS model, m.id AS make_id, mm.id AS model_id, lc.name AS category, ls.name AS subcategory\n",
    "FROM make m \n",
    "JOIN make_model mm ON m.id = mm.make_id \n",
    "JOIN lot_category lc ON lc.id = mm.category \n",
    "JOIN lot_subcategory ls ON ls.id = mm.subcategory \"\"\"\n",
    "mm_df = sql.pandas_execute(query)\n",
    "mm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run through finding the closest equipment match so we can pull in our category + subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_makes = mm_df[\"make\"].unique()\n",
    "\n",
    "def find_closest_match(row, mm_df):\n",
    "    # This function will search for the closest match of 'make' and 'model' in mm_df\n",
    "    closest_match_make = None\n",
    "    highest_make_score = 0\n",
    "    highest_model_score = 0\n",
    "    # get best match for make then sort through those models\n",
    "    for make in distinct_makes:\n",
    "        make_score = fuzz.ratio(row[\"Make\"].lower(), make.lower())\n",
    "        if make_score > highest_make_score:\n",
    "            highest_make_score = make_score\n",
    "            closest_match_make = make\n",
    "    mm_df_temp = mm_df[mm_df[\"make\"] == closest_match_make].copy()\n",
    "    for _, mm_row in mm_df_temp.iterrows():\n",
    "        # Compute similarity score for both make and model\n",
    "        model_score = fuzz.ratio(row[\"Model\"].lower(), mm_row[\"model\"].lower())\n",
    "\n",
    "\n",
    "        if model_score > highest_model_score:\n",
    "            highest_model_score = model_score\n",
    "            closest_match = mm_row\n",
    "\n",
    "\n",
    "    match = pd.Series({\"matched_make\": closest_match[\"make\"],\n",
    "                      \"matched_model\": closest_match[\"model\"],\n",
    "                      \"matched_category\": closest_match[\"category\"],\n",
    "                      \"matched_subcategory\": closest_match[\"subcategory\"],\n",
    "                      \"make_score\": highest_make_score,\n",
    "                      \"model_score\": highest_model_score})\n",
    "    # print make/model from row and the closest match\n",
    "    print(f\"From Dataset: {row['Make']} {row['Model']}, Closest match: {closest_match['make']} {closest_match['model']}, Score: {highest_make_score} {highest_model_score}\")\n",
    "    return match\n",
    "\n",
    "def parallel_match(df, mm_df):\n",
    "    # Create a ThreadPoolExecutor to handle multiple threads\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:  # Adjust max_workers based on your CPU core count\n",
    "        # Map each row to the find_closest_match function in parallel\n",
    "        futures = [executor.submit(find_closest_match, row, mm_df) for index, row in df.iterrows()]\n",
    "\n",
    "        # Collect the results as they complete\n",
    "        results = [future.result() for future in futures]\n",
    "\n",
    "    # Convert the list of results back to a dataframe\n",
    "    results_df = pd.DataFrame(results, columns=[\"matched_make\", \"matched_model\", \"matched_category\", \"matched_subcategory\", \"match_score\"])\n",
    "\n",
    "    # Merge the results back with the original dataframe\n",
    "    df = pd.concat([df.reset_index(drop=True), results_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the matching function to each row of df\n",
    "matched_df = parallel_match(df, mm_df)\n",
    "\n",
    "# Filter by a threshold if needed, for example, keeping only matches above 80%:\n",
    "threshold = 80\n",
    "matched_df = df[df[\"match_score\"] >= threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_account_names = [\"CONVERSION CUSTOMER\", \"MV EQUIP CONVERSION CUST\", \"21ST CENTURY LEASING LLC\", \"BIG IRON\", \"RANDALL BROTHERS\"]\n",
    "\n",
    "segment_df = df.copy()\n",
    "segment_df = segment_df.loc[segment_df[\"New/Used\"] == \"Used\"]\n",
    "segment_df = segment_df.loc[~segment_df[\"account_name\"].isin(bad_account_names)]\n",
    "segment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train/test dataset needs to be split temporally so if the prediction window is buy over next 12 months I need to cut off the dataset at the max date - 12 months to calculate some features like recency, frequency, and monetary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_WINDOW = 12 # months\n",
    "MAX_DATE = segment_df[\"Customer Invoice Date\"].max()\n",
    "segment_pre_df = segment_df.loc[segment_df[\"Customer Invoice Date\"] < MAX_DATE - pd.DateOffset(months=PREDICTION_WINDOW)].copy()\n",
    "segment_post_df = segment_df.loc[segment_df[\"Customer Invoice Date\"] >= MAX_DATE - pd.DateOffset(months=PREDICTION_WINDOW)].copy()\n",
    "# only include accounts in segment_pre_df in segment_post_df\n",
    "segment_post_df = segment_post_df.loc[segment_post_df[\"account_name\"].isin(segment_pre_df[\"account_name\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_pre_df.account_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_post_df.account_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 663 of accounts in training dataset have bought of the 7804 which is fairly imbalanced. Will have to address this.\n",
    "\n",
    "### Frequency\n",
    "Determine the number of purchases since min date and max date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_frequency_df = segment_pre_df.copy()\n",
    "segment_frequency_df = segment_frequency_df.sort_values(by=[\"account_name\", \"Customer Invoice Date\"], ascending = [True, True])\n",
    "segment_frequency_df = segment_frequency_df.groupby([\"account_name\", \"Product Group\"])[\"Customer Invoice Date\"].count().reset_index()\n",
    "segment_frequency_df.rename(columns={\"Customer Invoice Date\": \"Frequency\"}, inplace=True)\n",
    "segment_frequency_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency\n",
    "\n",
    "Get most recent purchase by account + category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_recency_df = segment_pre_df.copy()\n",
    "segment_recency_df = segment_recency_df.sort_values(by=[\"account_name\", \"Customer Invoice Date\"], ascending = [True, True])\n",
    "segment_recency_df = segment_recency_df.groupby([\"account_name\", \"Product Group\"])[\"Customer Invoice Date\"].max().reset_index()\n",
    "segment_recency_df[\"months_since_last_purchase\"] = (MAX_DATE - segment_recency_df[\"Customer Invoice Date\"]).dt.days / 30\n",
    "segment_recency_df[\"Recency\"] = segment_recency_df[\"months_since_last_purchase\"].astype(int)\n",
    "segment_recency_df = segment_recency_df[[\"account_name\", \"Product Group\", \"Recency\"]]\n",
    "segment_recency_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monetary\n",
    "\n",
    "Overall total by account + category from min to max date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_monetary_df = segment_pre_df.copy()\n",
    "segment_monetary_df = segment_monetary_df.groupby([\"account_name\", \"Product Group\"])[\"Customer Invoice Amount\"].sum().reset_index()\n",
    "segment_monetary_df.rename(columns={\"Customer Invoice Amount\": \"Monetary\"}, inplace=True)\n",
    "segment_monetary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_df = pd.merge(segment_frequency_df, segment_recency_df, on=[\"account_name\", \"Product Group\"], how=\"inner\")\n",
    "segment_training_df = pd.merge(segment_training_df, segment_monetary_df, on=[\"account_name\", \"Product Group\"], how=\"inner\")\n",
    "segment_training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally add in the flag for whether they purchased. If the account_name is in the post dataframe then they bought (1) otherwise they didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_df[\"Bought\"] = segment_training_df[\"account_name\"].isin(segment_post_df[\"account_name\"]).astype(int)\n",
    "segment_training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Crop\n",
    "\n",
    "Testing this on row crop tractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df = segment_training_df.copy()\n",
    "segment_training_row_crop_df = segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Product Group\"] == \"TRACTOR-ROW CROP\"]\n",
    "segment_training_row_crop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df[\"Bought\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positive_samples = segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 1].shape[0]\n",
    "train_df = pd.concat([segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 1], segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 0].sample(n=num_positive_samples)])\n",
    "#shuffle the dataframe\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"account_name\", \"Product Group\"], axis=1)\n",
    "X = train_df.drop(\"Bought\", axis=1)\n",
    "y = train_df[\"Bought\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the logistic regression model\n",
    "log_reg = LogisticRegression(random_state=69)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we did this as an ensemble where we downsample a bunch of times and create N models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positive_samples = segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 1].shape[0]\n",
    "num_models = 10\n",
    "model_list = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_models):\n",
    "    train_df = pd.concat([segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 1], segment_training_row_crop_df.loc[segment_training_row_crop_df[\"Bought\"] == 0].sample(n=num_positive_samples)])\n",
    "    #shuffle the dataframe\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    train_df = train_df.drop([\"account_name\", \"Product Group\"], axis=1)\n",
    "    X = train_df.drop(\"Bought\", axis=1)\n",
    "    y = train_df[\"Bought\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    scaler = StandardScaler()\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "    log_reg = LogisticRegression(random_state=69)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    model_list.append(log_reg)\n",
    "\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.sort_values(by=\"Monetary\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = segment_training_row_crop_df.drop([\"account_name\", \"Product Group\"], axis=1)\n",
    "X = pred_df.drop(\"Bought\", axis=1)\n",
    "y = pred_df[\"Bought\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "preds = []\n",
    "for model in model_list:\n",
    "    preds.append(model.predict(X))\n",
    "\n",
    "preds = np.array(preds)\n",
    "preds = np.mean(preds, axis=0)\n",
    "preds = preds > 0.5\n",
    "preds = preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df[\"predicted\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.loc[(segment_training_row_crop_df.Bought == 1) & (segment_training_row_crop_df.predicted == 1)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.loc[(segment_training_row_crop_df.Bought == 1) & (segment_training_row_crop_df.predicted == 0)].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the False Negative scenario the frequency & monetary tend to be smaller while recency is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.loc[(segment_training_row_crop_df.Bought == 0) & (segment_training_row_crop_df.predicted == 0)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_training_row_crop_df.loc[(segment_training_row_crop_df.Bought == 0) & (segment_training_row_crop_df.predicted == 1)].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_combines_df = segment_training_df.copy()\n",
    "segment_combines_df = segment_combines_df.loc[segment_combines_df[\"Product Group\"] == \"COMBINES\"]\n",
    "segment_combines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_combines_df[\"Bought\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positive_samples = segment_combines_df.loc[segment_combines_df[\"Bought\"] == 1].shape[0]\n",
    "num_models = 10\n",
    "model_list = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_models):\n",
    "    train_df = pd.concat([segment_combines_df.loc[segment_combines_df[\"Bought\"] == 1], segment_combines_df.loc[segment_combines_df[\"Bought\"] == 0].sample(n=num_positive_samples)])\n",
    "    #shuffle the dataframe\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    train_df = train_df.drop([\"account_name\", \"Product Group\"], axis=1)\n",
    "    X = train_df.drop(\"Bought\", axis=1)\n",
    "    y = train_df[\"Bought\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    scaler = StandardScaler()\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "    log_reg = LogisticRegression(random_state=69)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    model_list.append(log_reg)\n",
    "\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pocs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
